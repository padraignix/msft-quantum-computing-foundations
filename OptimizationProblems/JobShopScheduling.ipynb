{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: azure-quantum in c:\\users\\padra\\anaconda3\\lib\\site-packages (0.15.2101.126941)\nRequirement already satisfied: msal in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-quantum) (1.8.0)\nRequirement already satisfied: azure-devtools in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-quantum) (1.2.0)\nRequirement already satisfied: msrestazure in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-quantum) (0.6.4)\nRequirement already satisfied: azure-storage-blob in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-quantum) (12.7.1)\nRequirement already satisfied: cryptography<4,>=0.6 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msal->azure-quantum) (3.1.1)\nRequirement already satisfied: requests<3,>=2.0.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msal->azure-quantum) (2.24.0)\nRequirement already satisfied: PyJWT[crypto]<2,>=1.0.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msal->azure-quantum) (1.7.1)\nRequirement already satisfied: six>=1.10.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-devtools->azure-quantum) (1.15.0)\nRequirement already satisfied: vcrpy>=1.11.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-devtools->azure-quantum) (4.1.1)\nRequirement already satisfied: ConfigArgParse>=0.12.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-devtools->azure-quantum) (1.2.3)\nRequirement already satisfied: msrest<2.0.0,>=0.6.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msrestazure->azure-quantum) (0.6.21)\nRequirement already satisfied: adal<2.0.0,>=0.6.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msrestazure->azure-quantum) (1.2.6)\nRequirement already satisfied: azure-core<2.0.0,>=1.10.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from azure-storage-blob->azure-quantum) (1.10.0)\nRequirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from cryptography<4,>=0.6->msal->azure-quantum) (1.14.3)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->msal->azure-quantum) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->msal->azure-quantum) (1.25.11)\nRequirement already satisfied: idna<3,>=2.5 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->msal->azure-quantum) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->msal->azure-quantum) (3.0.4)\nRequirement already satisfied: wrapt in c:\\users\\padra\\anaconda3\\lib\\site-packages (from vcrpy>=1.11.0->azure-devtools->azure-quantum) (1.11.2)\nRequirement already satisfied: PyYAML in c:\\users\\padra\\anaconda3\\lib\\site-packages (from vcrpy>=1.11.0->azure-devtools->azure-quantum) (5.3.1)\nRequirement already satisfied: yarl; python_version >= \"3.6\" in c:\\users\\padra\\anaconda3\\lib\\site-packages (from vcrpy>=1.11.0->azure-devtools->azure-quantum) (1.6.3)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msrest<2.0.0,>=0.6.0->msrestazure->azure-quantum) (1.3.0)\nRequirement already satisfied: isodate>=0.6.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from msrest<2.0.0,>=0.6.0->msrestazure->azure-quantum) (0.6.0)\nRequirement already satisfied: python-dateutil<3,>=2.1.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from adal<2.0.0,>=0.6.0->msrestazure->azure-quantum) (2.8.1)\nRequirement already satisfied: pycparser in c:\\users\\padra\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography<4,>=0.6->msal->azure-quantum) (2.20)\nRequirement already satisfied: multidict>=4.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from yarl; python_version >= \"3.6\"->vcrpy>=1.11.0->azure-devtools->azure-quantum) (5.1.0)\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\padra\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest<2.0.0,>=0.6.0->msrestazure->azure-quantum) (3.1.0)\nNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<msrest.authentication.BasicTokenAuthentication at 0x247b4058070>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from azure.quantum import Workspace\n",
    "from typing import List\n",
    "from azure.quantum.optimization import Term\n",
    "\n",
    "# Copy the settings for your workspace below\n",
    "workspace = Workspace(\n",
    "    subscription_id=    \"f972c3c0-1413-449c-b4e9-33e27d60f573\", # add your subscription_id\n",
    "    resource_group=     \"Quantum1\", # add your resource_group\n",
    "    name=               \"quantum-computing-foundations\", # add your workspace name\n",
    "    location=           \"eastus\"  # add your workspace location (for example, \"westus\")\n",
    ")\n",
    "\n",
    "workspace.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(jobs_ops_map:dict, machines_ops_map:dict, processing_time:dict, T:int):\n",
    "    \"\"\"\n",
    "    Process & validate problem parameters (config) and generate inverse dict of operations to jobs.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    machines_ops_map(dict): Mapping of operations to machines, e.g.:\n",
    "        machines_ops_map = {\n",
    "            0: [0,1],          # Operations 0 & 1 assigned to machine 0\n",
    "            1: [2,3]           # Operations 2 & 3 assigned to machine 1\n",
    "        }\n",
    "    processing_time (dict): Operation processing times\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Problem cannot take longer to complete than all operations executed sequentially\n",
    "    ## Sum all operation processing times to calculate the maximum makespan\n",
    "    T = min(sum(processing_time.values()), T) \n",
    "\n",
    "    # Ensure operation assignments to machines are sorted in ascending order\n",
    "    for m, ops in machines_ops_map.items():\n",
    "        machines_ops_map[m] = sorted(ops)\n",
    "    ops_jobs_map = {}\n",
    "\n",
    "    for job, ops in jobs_ops_map.items():\n",
    "        # Fail if operation IDs within a job are out of order\n",
    "        assert (ops == sorted(ops)), f\"Operation IDs within a job must be in ascending order. Job was: {job}: {ops}\"\n",
    "\n",
    "        for op in ops:\n",
    "            # Fail if there are duplicate operation IDs\n",
    "            assert (op not in ops_jobs_map.keys()), f\"Operation IDs must be unique. Duplicate ID was: {op}\"\n",
    "            ops_jobs_map[op] = job\n",
    "\n",
    "    return ops_jobs_map, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set problem parameters\n",
    "## Allowed time (jobs can only be scheduled below this limit)\n",
    "T = 10\n",
    "\n",
    "## Processing time for each operation\n",
    "processing_time = {0: 2, 1: 1, 2: 2, 3: 2, 4: 1, 5: 2}\n",
    "\n",
    "## Assignment of operations to jobs (job ID: [operation IDs])\n",
    "### Operation IDs within a job must be in ascending order\n",
    "jobs_ops_map = {\n",
    "    0: [0, 1], # Restart life support\n",
    "    1: [2, 3], # Recalibrate navigation system\n",
    "    2: [4, 5]  # Replace power transformer in the reactor\n",
    "}\n",
    "\n",
    "## Assignment of operations to machines\n",
    "### Three jobs, two machines\n",
    "machines_ops_map = {\n",
    "    0: [0, 1, 4, 5], # Operations 0, 1, 4 and 5 are assigned to machine 0 (the universal multi-tool)\n",
    "    1: [2, 3]        # Operations 2 & 3 are assigned to machine 1 (the ship computer)\n",
    "}\n",
    "\n",
    "## Inverse mapping of jobs to operations\n",
    "ops_jobs_map, T = process_config(jobs_ops_map, machines_ops_map, processing_time, T)"
   ]
  },
  {
   "source": [
    "The precedence constraint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precedence_constraint(jobs_ops_map:dict, T:int, processing_time:dict, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the precedence constraint.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # Loop through all jobs:\n",
    "    for ops in jobs_ops_map.values():\n",
    "        # Loop through all operations in this job:\n",
    "        for i in range(len(ops) - 1):\n",
    "            for t in range(0, T):\n",
    "                # Loop over times that would violate the constraint:\n",
    "                for s in range(0, min(t + processing_time[ops[i]], T)):\n",
    "                    # Assign penalty\n",
    "                    terms.append(Term(c=weight, indices=[ops[i]*T+t, (ops[i+1])*T+s]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "source": [
    "The operation-once constraint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation_once_constraint(ops_jobs_map:dict, T:int, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the operation once constraint.\n",
    "    Penalty function is of form: 2xy - x - y + 1\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    ops_jobs_map (dict): Map of operations to jobs {op: job}\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # 2xy - x - y parts of the constraint function\n",
    "    # Loop through all operations\n",
    "    for op in ops_jobs_map.keys():\n",
    "        for t in range(T):\n",
    "            # - x - y terms\n",
    "            terms.append(Term(c=weight*-1, indices=[op*T+t]))\n",
    "\n",
    "            # + 2xy term\n",
    "            # Loop through all other start times for the same job\n",
    "            # to get the cross terms\n",
    "            for s in range(t+1, T):\n",
    "                terms.append(Term(c=weight*2, indices=[op*T+t, op*T+s]))\n",
    "\n",
    "    # + 1 term\n",
    "    terms.append(Term(c=weight*1, indices=[]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "source": [
    "The no-overlap constraint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_overlap_constraint(T:int, processing_time:dict, ops_jobs_map:dict, machines_ops_map:dict, weight:float):\n",
    "    \"\"\"\n",
    "    Construct penalty terms for the no overlap constraint.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    weight (float): Relative importance of this constraint\n",
    "    ops_jobs_map (dict): Map of operations to jobs {op: job}\n",
    "    machines_ops_map(dict): Mapping of operations to machines, e.g.:\n",
    "        machines_ops_map = {\n",
    "            0: [0,1],          # Operations 0 & 1 assigned to machine 0\n",
    "            1: [2,3]           # Operations 2 & 3 assigned to machine 1\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    # For each machine\n",
    "    for ops in machines_ops_map.values():\n",
    "        # Loop over each operation i requiring this machine\n",
    "        for i in ops:\n",
    "            # Loop over each operation k requiring this machine \n",
    "            for k in ops:\n",
    "                # Loop over simulation time\n",
    "                for t in range(T):\n",
    "                    # When i != k (when scheduling two different operations)\n",
    "                    if i != k:\n",
    "                        # t = s meaning two operations are scheduled to start at the same time on the same machine\n",
    "                        terms.append(Term(c=weight*1, indices=[i*T+t, k*T+t]))\n",
    "\n",
    "                        # Add penalty when operation runtimes overlap\n",
    "                        for s in range(t, min(t + processing_time[i], T)):\n",
    "                            terms.append(Term(c=weight*1, indices=[i*T+t, k*T+s]))  \n",
    "\n",
    "                        # If operations are in the same job, penalize for the extra time 0 -> t (operations scheduled out of order)\n",
    "                        if ops_jobs_map[i] == ops_jobs_map[k]:\n",
    "                            for s in range(0, t):\n",
    "                                if i < k:\n",
    "                                    terms.append(Term(c=weight*1, indices=[i*T+t, k*T+s]))  \n",
    "                                if i > k:\n",
    "                                    terms.append(Term(c=weight*1, indices=[i*T+s, k*T+t]))  \n",
    "\n",
    "    return terms"
   ]
  },
  {
   "source": [
    "Minimizing the makespan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_penalty(t:int, m_count:int, t0:int): \n",
    "    assert m_count > 1                           # Ensure you don't divide by 0\n",
    "    return (m_count**(t - t0) - 1)/float(m_count - 1)\n",
    "\n",
    "def makespan_objective(T:int, processing_time:dict, jobs_ops_map:dict, m_count:int, weight:float):\n",
    "    \"\"\"\n",
    "    Construct makespan minimization terms.\n",
    "\n",
    "    Keyword arguments:\n",
    "\n",
    "    T (int): Allowed time (jobs can only be scheduled below this limit)\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    m_count (int): Number of machines\n",
    "    weight (float): Relative importance of this constraint\n",
    "    \"\"\"\n",
    "\n",
    "    terms = []\n",
    "\n",
    "    lower_bound = max([sum([processing_time[i] for i in job]) for job in jobs_ops_map.values()])\n",
    "    upper_bound = T\n",
    "\n",
    "    # Loop through the final operation of each job\n",
    "    for job in jobs_ops_map.values():\n",
    "        i = job[-1]\n",
    "        # Loop through each time step the operation could be completion at\n",
    "        for t in range(lower_bound + 1, T + processing_time[i]):\n",
    "            terms.append(Term(c=weight*(calc_penalty(t, m_count, lower_bound)), indices=[i*T + (t - processing_time[i])]))\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "source": [
    "Weights of penalties"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate terms to submit to solver using functions defined previously\n",
    "## Assign penalty term weights:\n",
    "alpha = 5  # Precedence constraint\n",
    "beta = 5   # Operation once constraint\n",
    "gamma = 5  # No overlap constraint\n",
    "delta = 0.004  # Makespan minimization (objective function)\n",
    "\n",
    "## Build terms\n",
    "### Constraints:\n",
    "c1 = precedence_constraint(jobs_ops_map, T, processing_time, alpha)\n",
    "c2 = operation_once_constraint(ops_jobs_map, T, beta)\n",
    "c3 = no_overlap_constraint(T, processing_time, ops_jobs_map, machines_ops_map, gamma)\n",
    "\n",
    "### Objective function\n",
    "c4 = makespan_objective(T, processing_time, jobs_ops_map, len(machines_ops_map), delta)\n",
    "\n",
    "### Combine terms:\n",
    "terms = []\n",
    "terms = c1 + c2 + c3 + c4"
   ]
  },
  {
   "source": [
    "Running the job"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "..{'0': 0, '10': 0, '11': 0, '1': 1, '12': 0, '2': 0, '13': 1, '3': 0, '14': 0, '4': 0, '15': 0, '5': 0, '16': 0, '6': 0, '17': 0, '7': 0, '18': 0, '8': 0, '19': 0, '9': 0, '20': 1, '30': 0, '31': 0, '21': 0, '32': 1, '22': 0, '33': 0, '23': 0, '34': 0, '24': 0, '35': 0, '25': 0, '36': 0, '26': 0, '37': 0, '27': 0, '38': 0, '28': 0, '39': 0, '29': 0, '40': 1, '50': 0, '41': 0, '51': 0, '42': 0, '52': 0, '43': 0, '53': 0, '44': 0, '54': 1, '45': 0, '55': 0, '46': 0, '56': 0, '47': 0, '57': 0, '48': 0, '58': 0, '49': 0, '59': 0}\n"
     ]
    }
   ],
   "source": [
    "from azure.quantum.optimization import Problem, ProblemType\n",
    "from azure.quantum.optimization import SimulatedAnnealing # Change this line to match the Azure Quantum Optimization solver type you wish to use\n",
    "\n",
    "# Problem type is PUBO in this instance. You could also have chosen to represent the problem in Ising form.\n",
    "problem = Problem(name=\"Job shop sample\", problem_type=ProblemType.pubo, terms=terms)\n",
    "\n",
    "# Provide details of your workspace, created at the beginning of this tutorial\n",
    "# Provide the name of the solver you wish to use for this problem (as imported above)\n",
    "solver = SimulatedAnnealing(workspace, timeout = 100) # Timeout in seconds\n",
    "\n",
    "# Run job synchronously\n",
    "result = solver.optimize(problem)\n",
    "config = result['configuration']\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "source": [
    "Run Asynchronously"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1d3f9c16-68d4-11eb-bd92-b06ebf2dc0e6\n",
      "Waiting\n",
      "{'0': 0, '10': 0, '11': 0, '1': 1, '12': 0, '2': 0, '13': 1, '3': 0, '14': 0, '4': 0, '15': 0, '5': 0, '16': 0, '6': 0, '17': 0, '7': 0, '18': 0, '8': 0, '19': 0, '9': 0, '20': 1, '30': 0, '31': 0, '21': 0, '32': 1, '22': 0, '33': 0, '23': 0, '34': 0, '24': 0, '35': 0, '25': 0, '36': 0, '26': 0, '37': 0, '27': 0, '38': 0, '28': 0, '39': 0, '29': 0, '40': 1, '50': 0, '41': 0, '51': 0, '42': 0, '52': 0, '43': 0, '53': 0, '44': 0, '54': 1, '45': 0, '55': 0, '46': 0, '56': 0, '47': 0, '57': 0, '48': 0, '58': 0, '49': 0, '59': 0}\n"
     ]
    }
   ],
   "source": [
    "# Submit problem to solver\n",
    "job = solver.submit(problem)\n",
    "print(job.id)\n",
    "\n",
    "# Get job status\n",
    "job.refresh()\n",
    "print(job.details.status)\n",
    "\n",
    "# Get results\n",
    "result = job.get_results()\n",
    "config = result['configuration']\n",
    "print(config)"
   ]
  },
  {
   "source": [
    "Map variables to operations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_array(config: dict):\n",
    "    \"\"\"\n",
    "    Create array from returned config dict.\n",
    "\n",
    "    Keyword arguments:\n",
    "    config (dictionary): config returned from solver\n",
    "    \"\"\"\n",
    "\n",
    "    variables = []\n",
    "    for key, val in config.items():\n",
    "        variables.insert(int(key), val)\n",
    "    return variables\n",
    "\n",
    "def print_problem_details(ops_jobs_map:dict, processing_time:dict, machines_ops_map:dict):\n",
    "    \"\"\"\n",
    "\n",
    "    Print problem details e.g. operation runtimes and machine assignments.        \n",
    "\n",
    "    Keyword arguments:\n",
    "    ops_jobs_map (dict): Map of operations to jobs {operation: job}\n",
    "    processing_time (dict): Operation processing times\n",
    "    machines_ops_map(dict): Mapping of machines to operations\n",
    "    \"\"\"\n",
    "\n",
    "    machines = [None] * len(ops_jobs_map)\n",
    "\n",
    "    for m, ops in machines_ops_map.items():\n",
    "        for op in ops:\n",
    "          machines[op] = m\n",
    "\n",
    "    print(f\"           Job ID: {list(ops_jobs_map.values())}\")\n",
    "    print(f\"     Operation ID: {list(ops_jobs_map.keys())}\")\n",
    "    print(f\"Operation runtime: {list(processing_time.values())}\")\n",
    "    print(f\" Assigned machine: {machines}\")\n",
    "    print()\n",
    "\n",
    "def split_array(T:int, array:List[int]):\n",
    "    \"\"\"\n",
    "    Split array into rows representing the rows of our operation matrix.\n",
    "\n",
    "    Keyword arguments:\n",
    "    T (int): Time allowed to complete all operations\n",
    "    array (List[int]): array of x_i,t values generated from config returned by solver\n",
    "    \"\"\"\n",
    "\n",
    "    ops = []\n",
    "    i = 0\n",
    "    while i < len(array):\n",
    "        x = array[i:i+T]\n",
    "        ops.append(x)\n",
    "        i = i + T\n",
    "    return ops\n",
    "\n",
    "def print_matrix(T:int, matrix:List[List[int]]):\n",
    "    \"\"\"\n",
    "    Print final output matrix.        \n",
    "\n",
    "    Keyword arguments:\n",
    "    T (int): Time allowed to complete all operations\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    \"\"\"\n",
    "\n",
    "    labels = \"    t:\"\n",
    "    for t in range(0, T):\n",
    "        labels += f\" {t}\"\n",
    "    print(labels)\n",
    "\n",
    "    idx = 0\n",
    "    for row in matrix:\n",
    "        print(\"x_\" + str(idx) + \",t: \", end=\"\")\n",
    "        print(' '.join(map(str,row)))\n",
    "        idx += 1\n",
    "    print()\n",
    "\n",
    "def extract_start_times(jobs_ops_map:dict, matrix:List[List[int]]):\n",
    "    \"\"\"\n",
    "    Extract operation start times & group them into jobs.\n",
    "\n",
    "    Keyword arguments:\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    \"\"\"\n",
    "    #jobs = {}\n",
    "    jobs = [None] * len(jobs_ops_map)\n",
    "    op_start_times = []\n",
    "    for job, ops in jobs_ops_map.items(): \n",
    "        x = [None] * len(ops)\n",
    "        for i in range(len(ops)):\n",
    "            try :\n",
    "                x[i] = matrix[ops[i]].index(1)\n",
    "                op_start_times.append(matrix[ops[i]].index(1))\n",
    "            except ValueError:\n",
    "                x[i] = -1\n",
    "                op_start_times.append(-1)\n",
    "        jobs[job] = x\n",
    "\n",
    "    return jobs, op_start_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Config dict:\n{'0': 0, '10': 0, '11': 0, '1': 1, '12': 0, '2': 0, '13': 1, '3': 0, '14': 0, '4': 0, '15': 0, '5': 0, '16': 0, '6': 0, '17': 0, '7': 0, '18': 0, '8': 0, '19': 0, '9': 0, '20': 1, '30': 0, '31': 0, '21': 0, '32': 1, '22': 0, '33': 0, '23': 0, '34': 0, '24': 0, '35': 0, '25': 0, '36': 0, '26': 0, '37': 0, '27': 0, '38': 0, '28': 0, '39': 0, '29': 0, '40': 1, '50': 0, '41': 0, '51': 0, '42': 0, '52': 0, '43': 0, '53': 0, '44': 0, '54': 1, '45': 0, '55': 0, '46': 0, '56': 0, '47': 0, '57': 0, '48': 0, '58': 0, '49': 0, '59': 0}\n\nConfig array:\n[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n\n           Job ID: [0, 0, 1, 1, 2, 2]\n     Operation ID: [0, 1, 2, 3, 4, 5]\nOperation runtime: [2, 1, 2, 2, 1, 2]\n Assigned machine: [0, 0, 1, 1, 0, 0]\n\nOperation matrix:\n    t: 0 1 2 3 4 5 6 7 8 9\nx_0,t: 0 1 0 0 0 0 0 0 0 0\nx_1,t: 0 0 0 1 0 0 0 0 0 0\nx_2,t: 1 0 0 0 0 0 0 0 0 0\nx_3,t: 0 0 1 0 0 0 0 0 0 0\nx_4,t: 1 0 0 0 0 0 0 0 0 0\nx_5,t: 0 0 0 0 1 0 0 0 0 0\n\nOperation start times (grouped into jobs):\n[[1, 3], [0, 2], [0, 4]]\n\nMakespan (time taken to complete all operations): 6\n"
     ]
    }
   ],
   "source": [
    "# Produce 1D array of x_i,t = 0, 1 representing when each operation starts\n",
    "op_array = create_op_array(config) \n",
    "\n",
    "# Print config details:\n",
    "print(f\"Config dict:\\n{config}\\n\")\n",
    "print(f\"Config array:\\n{op_array}\\n\")\n",
    "\n",
    "# Print problem setup\n",
    "print_problem_details(ops_jobs_map, processing_time, machines_ops_map)\n",
    "\n",
    "# Print final operation matrix, using the returned config\n",
    "print(\"Operation matrix:\")\n",
    "matrix = split_array(T, op_array) \n",
    "print_matrix(T, matrix)\n",
    "\n",
    "# Find where each operation starts (when x_i,t = 1) and return the start time\n",
    "print(\"Operation start times (grouped into jobs):\")\n",
    "jobs, op_start_times = extract_start_times(jobs_ops_map, matrix)\n",
    "print(jobs)\n",
    "\n",
    "# Calculate makespan (time taken to complete all operations - the objective you are minimizing)\n",
    "op_end_times = [op_start_times[i] + processing_time[i] for i in range(len(op_start_times))]\n",
    "makespan = max(op_end_times)\n",
    "\n",
    "print(f\"\\nMakespan (time taken to complete all operations): {makespan}\")"
   ]
  },
  {
   "source": [
    "Solution Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           Job ID: [0, 0, 1, 1, 2, 2]\n     Operation ID: [0, 1, 2, 3, 4, 5]\nOperation runtime: [2, 1, 2, 2, 1, 2]\n Assigned machine: [0, 0, 1, 1, 0, 0]\n\nAzure Quantum solution:\n    t: 0 1 2 3 4 5 6 7 8 9\nx_0,t: 0 1 0 0 0 0 0 0 0 0\nx_1,t: 0 0 0 1 0 0 0 0 0 0\nx_2,t: 1 0 0 0 0 0 0 0 0 0\nx_3,t: 0 0 1 0 0 0 0 0 0 0\nx_4,t: 1 0 0 0 0 0 0 0 0 0\nx_5,t: 0 0 0 0 1 0 0 0 0 0\n\nOperation start times (grouped into jobs):\n[[1, 3], [0, 2], [0, 4]]\n\nSolution is valid.\n\n"
     ]
    }
   ],
   "source": [
    "def check_precedence(processing_time, jobs):\n",
    "    \"\"\"\n",
    "    Check if the solution violates the precedence constraint.\n",
    "    Returns True if the constraint is violated.\n",
    "\n",
    "    Keyword arguments:\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs (List[List[int]]): List of operation start times, grouped into jobs\n",
    "    \"\"\"\n",
    "\n",
    "    op_id = 0\n",
    "    for job in jobs:\n",
    "        for i in range(len(job) - 1):\n",
    "            if job[i+1] - job[i] < processing_time[op_id]:\n",
    "                return True\n",
    "            op_id += 1\n",
    "        op_id += 1\n",
    "    return False\n",
    "\n",
    "def check_operation_once(matrix):\n",
    "    \"\"\"\n",
    "    Check if the solution violates the operation once constraint.\n",
    "    Returns True if the constraint is violated.\n",
    "\n",
    "    Keyword arguments:\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    \"\"\"\n",
    "    for x_it_vals in matrix:\n",
    "        if sum(x_it_vals) != 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_no_overlap(op_start_times:list, machines_ops_map:dict, processing_time:dict):\n",
    "    \"\"\"\n",
    "    Check if the solution violates the no overlap constraint.\n",
    "    Returns True if the constraint is violated.\n",
    "\n",
    "    Keyword arguments:\n",
    "    op_start_times (list): Start times for the operations\n",
    "    machines_ops_map(dict): Mapping of machines to operations\n",
    "    processing_time (dict): Operation processing times\n",
    "    \"\"\"\n",
    "    pvals = list(processing_time.values())\n",
    "\n",
    "    # For each machine\n",
    "    for ops in machines_ops_map.values():\n",
    "        machine_start_times = [op_start_times[i] for i in ops]\n",
    "        machine_pvals = [pvals[i] for i in ops]\n",
    "\n",
    "        # Two operations start at the same time on the same machine\n",
    "        if len(machine_start_times) != len(set(machine_start_times)):\n",
    "            return True\n",
    "\n",
    "        # There is overlap in the runtimes of two operations assigned to the same machine\n",
    "        machine_start_times, machine_pvals = zip(*sorted(zip(machine_start_times, machine_pvals)))\n",
    "        for i in range(len(machine_pvals) - 1):\n",
    "            if machine_start_times[i] + machine_pvals[i] > machine_start_times[i+1]:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def validate_solution(matrix:dict, machines_ops_map:dict, processing_time:dict, jobs_ops_map:dict):\n",
    "    \"\"\"\n",
    "    Check that solution has not violated any constraints. \n",
    "    Returns True if the solution is valid.\n",
    "\n",
    "    Keyword arguments:\n",
    "    matrix (List[List[int]]): Matrix of x_i,t values\n",
    "    machines_ops_map(dict): Mapping of machines to operations\n",
    "    processing_time (dict): Operation processing times\n",
    "    jobs_ops_map (dict): Map of jobs to operations {job: [operations]}\n",
    "    \"\"\"\n",
    "\n",
    "    jobs, op_start_times = extract_start_times(jobs_ops_map, matrix)\n",
    "\n",
    "    # Check if constraints are violated\n",
    "    precedence_violated = check_precedence(processing_time, jobs)\n",
    "    operation_once_violated = check_operation_once(matrix)\n",
    "    no_overlap_violated = check_no_overlap(op_start_times, machines_ops_map, processing_time)\n",
    "\n",
    "    if not precedence_violated and not operation_once_violated and not no_overlap_violated:\n",
    "        print(\"Solution is valid.\\n\")\n",
    "    else:\n",
    "        print(\"Solution not valid. Details:\")\n",
    "        print(f\"\\tPrecedence constraint violated: {precedence_violated}\")\n",
    "        print(f\"\\tOperation once constraint violated: {operation_once_violated}\")\n",
    "        print(f\"\\tNo overlap constraint violated: {no_overlap_violated}\\n\")\n",
    "\n",
    "print_problem_details(ops_jobs_map, processing_time, machines_ops_map)\n",
    "\n",
    "print(\"Azure Quantum solution:\")\n",
    "print_matrix(T, matrix)\n",
    "\n",
    "print(\"Operation start times (grouped into jobs):\")\n",
    "print(jobs)\n",
    "print()\n",
    "\n",
    "validate_solution(matrix, machines_ops_map, processing_time, jobs_ops_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}